package SystemDesign;

/**
 * it was a framework that allowed engineers or systems administrators to process very large data sets
 * that were spread across hundreds or thousands of machines, so in a distributed setting, very efficiently, quickly
 * and in a fault-tolerant manner.
 *
 * Data processing tasks could be split up or refactored so to speak into two steps a Map step and a Reduce step.
 * And these two steps of the Map and the Reduce were inspired by the Map and Reduce functions that a lot of functional programming languages have.
 *
 * You've got a data set that's spread across multiple machines you have some Map function that you the engineer
 * or systems administrator is gonna specify, that Map function is gonna transform your data set into intermediate values,
 * these key value pairs, and then these key value pairs as for being reorganized in some way are gonna be reduced
 * in some final step into some final output.
 *
 * @etcd
 * https://etcd.io/
 *
 * @ZooKeeper
 * https://zookeeper.apache.org/
 * 
 */
public class MapReduce
{

}
